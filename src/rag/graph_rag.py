"""
GraphRAG implementation using existing Supabase schema
Uses: companies, company_relationships, documents tables
"""

import os
import json
import logging
from typing import List, Dict, Optional
import networkx as nx
from openai import OpenAI
from supabase import create_client, Client
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)


class GraphRAG:
    """
    Graph-based RAG using existing Supabase tables:
    - companies: íšŒì‚¬ ì •ë³´
    - company_relationships: íšŒì‚¬ ê°„ ê´€ê³„
    - documents: ë²¡í„° ë¬¸ì„œ
    """

    def __init__(
        self, embedding_model: str = "text-embedding-3-small", llm_model: str = "gpt-4o-mini"
    ):
        """Initialize GraphRAG with Supabase"""

        # OpenAI client
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        if not self.openai_api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        self.openai_client = OpenAI(api_key=self.openai_api_key)
        self.embedding_model = embedding_model
        self.llm_model = llm_model

        # Supabase client
        supabase_url = os.getenv("SUPABASE_URL")
        supabase_key = os.getenv("SUPABASE_KEY")

        if not supabase_url or not supabase_key:
            raise ValueError("SUPABASE_URLê³¼ SUPABASE_KEY í™˜ê²½ ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        self.supabase: Client = create_client(supabase_url, supabase_key)

        # Local graph for analysis
        self.local_graph = nx.DiGraph()

        logger.info("GraphRAG initialized with Supabase")

    def _get_embedding(self, text: str) -> List[float]:
        """Generate embedding for text"""
        response = self.openai_client.embeddings.create(model=self.embedding_model, input=text)
        return response.data[0].embedding

    def _chat_completion(self, system_prompt: str, user_prompt: str) -> str:
        """Get chat completion from OpenAI"""
        response = self.openai_client.chat.completions.create(
            model=self.llm_model,
            temperature=0.1,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
        )
        return response.choices[0].message.content

    def extract_relationships(self, text: str, source_ticker: Optional[str] = None) -> List[Dict]:
        """Extract company relationships from text using LLM"""

        system_prompt = """You are a financial analyst. Extract company relationships from text.

Relationship types: partnership, acquisition, supplier, customer, competitor, subsidiary, investment

Return JSON only:
[{"source_company": "...", "source_ticker": "...", "target_company": "...", "target_ticker": "...", 
  "relationship_type": "...", "confidence": 0.8}]"""

        user_prompt = f"Source Company Ticker: {source_ticker or 'Unknown'}\n\nText:\n{text[:3000]}"

        try:
            response = self._chat_completion(system_prompt, user_prompt)

            # Clean JSON
            response = response.strip()
            if response.startswith("```"):
                response = response.split("```")[1]
                if response.startswith("json"):
                    response = response[4:]

            return json.loads(response.strip())

        except Exception as e:
            logger.error(f"Extraction error: {e}")
            return []

    def save_relationships(
        self, relationships: List[Dict], extracted_from: str = None, filing_date: str = None
    ) -> int:
        """Save relationships to company_relationships table"""
        if not relationships:
            return 0

        records = []
        for rel in relationships:
            records.append(
                {
                    "source_company": rel.get("source_company", ""),
                    "source_ticker": rel.get("source_ticker", ""),
                    "target_company": rel.get("target_company", ""),
                    "target_ticker": rel.get("target_ticker", ""),
                    "relationship_type": rel.get("relationship_type", "related"),
                    "confidence": rel.get("confidence", 0.5),
                    "extracted_from": extracted_from,
                    "filing_date": filing_date,
                }
            )

        try:
            self.supabase.table("company_relationships").insert(records).execute()
            return len(records)
        except Exception as e:
            logger.error(f"Error saving relationships: {e}")
            return 0

    def find_relationships(self, ticker: str, relationship_type: Optional[str] = None) -> Dict:
        """Find relationships for a company by ticker"""
        try:
            # Outgoing relationships (source)
            query = (
                self.supabase.table("company_relationships").select("*").eq("source_ticker", ticker)
            )
            if relationship_type:
                query = query.eq("relationship_type", relationship_type)
            outgoing = query.execute().data

            # Incoming relationships (target)
            query = (
                self.supabase.table("company_relationships").select("*").eq("target_ticker", ticker)
            )
            if relationship_type:
                query = query.eq("relationship_type", relationship_type)
            incoming = query.execute().data

            return {
                "ticker": ticker,
                "outgoing": outgoing,
                "incoming": incoming,
                "total": len(outgoing) + len(incoming),
            }

        except Exception as e:
            logger.error(f"Error finding relationships: {e}")
            return {"ticker": ticker, "outgoing": [], "incoming": [], "error": str(e)}

    def get_company(self, ticker: str) -> Optional[Dict]:
        """Get company info by ticker"""
        try:
            result = self.supabase.table("companies").select("*").eq("ticker", ticker).execute()
            return result.data[0] if result.data else None
        except Exception as e:
            logger.error(f"Error getting company: {e}")
            return None

    def search_companies(self, query: str, limit: int = 10) -> List[Dict]:
        """Search companies by name"""
        try:
            result = (
                self.supabase.table("companies")
                .select("*")
                .ilike("company_name", f"%{query}%")
                .limit(limit)
                .execute()
            )
            return result.data
        except Exception as e:
            logger.error(f"Error searching companies: {e}")
            return []

    def get_company_network(self, ticker: str, depth: int = 1) -> Dict:
        """Get company relationship network"""
        visited = set()
        network = {"nodes": [], "edges": []}

        def traverse(current_ticker: str, current_depth: int):
            if current_depth > depth or current_ticker in visited:
                return
            visited.add(current_ticker)

            # Add node
            company = self.get_company(current_ticker)
            if company:
                network["nodes"].append(
                    {
                        "id": current_ticker,
                        "name": company.get("company_name", current_ticker),
                        "sector": company.get("sector", ""),
                    }
                )

            # Get relationships
            rels = self.find_relationships(current_ticker)

            for rel in rels.get("outgoing", []):
                target = rel.get("target_ticker")
                if target:
                    network["edges"].append(
                        {
                            "source": current_ticker,
                            "target": target,
                            "type": rel.get("relationship_type", "related"),
                        }
                    )
                    traverse(target, current_depth + 1)

            for rel in rels.get("incoming", []):
                source = rel.get("source_ticker")
                if source:
                    network["edges"].append(
                        {
                            "source": source,
                            "target": current_ticker,
                            "type": rel.get("relationship_type", "related"),
                        }
                    )
                    traverse(source, current_depth + 1)

        traverse(ticker, 0)
        return network

    def query_with_context(self, query: str, ticker: Optional[str] = None) -> Dict:
        """Query with relationship context"""

        # Get context
        context_parts = []

        if ticker:
            # Company info
            company = self.get_company(ticker)
            if company:
                context_parts.append(f"Company: {company.get('company_name')} ({ticker})")
                context_parts.append(f"Sector: {company.get('sector', 'N/A')}")
                context_parts.append(f"Industry: {company.get('industry', 'N/A')}")

            # Relationships
            rels = self.find_relationships(ticker)
            if rels["total"] > 0:
                context_parts.append("\nRelationships:")
                for rel in rels.get("outgoing", [])[:10]:
                    context_parts.append(
                        f"  â†’ {rel['relationship_type']}: {rel['target_company']} ({rel.get('target_ticker', '')})"
                    )
                for rel in rels.get("incoming", [])[:10]:
                    context_parts.append(
                        f"  â† {rel['relationship_type']}: {rel['source_company']} ({rel.get('source_ticker', '')})"
                    )

        context_str = (
            "\n".join(context_parts) if context_parts else "No specific context available."
        )

        # Generate response
        system_prompt = """You are a financial analyst assistant. Answer based on the company and relationship context.
Be specific and cite relationships when relevant. Answer in Korean."""

        user_prompt = f"Context:\n{context_str}\n\nQuestion: {query}"

        response = self._chat_completion(system_prompt, user_prompt)

        return {"query": query, "ticker": ticker, "response": response, "context": context_str}

    def build_local_graph(self) -> int:
        """
        Supabaseì˜ ê´€ê³„ ë°ì´í„°ë¥¼ NetworkX ê·¸ë˜í”„ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.
        Returns: ë¡œë“œëœ ì—£ì§€ ìˆ˜
        """
        try:
            # ëª¨ë“  ê´€ê³„ ê°€ì ¸ì˜¤ê¸°
            result = self.supabase.table("company_relationships").select("*").execute()
            relationships = result.data or []
            
            # ê·¸ë˜í”„ ì´ˆê¸°í™”
            self.local_graph.clear()
            
            for rel in relationships:
                source = rel.get("source_ticker")
                target = rel.get("target_ticker")
                rel_type = rel.get("relationship_type", "related")
                confidence = rel.get("confidence", 0.5)
                
                if source and target:
                    # ë…¸ë“œ ì¶”ê°€ (ìë™ìœ¼ë¡œ ì¤‘ë³µ ë°©ì§€)
                    self.local_graph.add_node(source, name=rel.get("source_company", source))
                    self.local_graph.add_node(target, name=rel.get("target_company", target))
                    
                    # ì—£ì§€ ì¶”ê°€ (ê´€ê³„ ìœ í˜•ê³¼ ì‹ ë¢°ë„ë¥¼ ì†ì„±ìœ¼ë¡œ)
                    self.local_graph.add_edge(
                        source, target,
                        relationship_type=rel_type,
                        confidence=confidence,
                        weight=1 - confidence  # ì‹ ë¢°ë„ê°€ ë†’ì„ìˆ˜ë¡ ê±°ë¦¬ê°€ ì§§ìŒ
                    )
            
            logger.info(f"Built local graph: {self.local_graph.number_of_nodes()} nodes, {self.local_graph.number_of_edges()} edges")
            return self.local_graph.number_of_edges()
            
        except Exception as e:
            logger.error(f"Error building local graph: {e}")
            return 0

    def get_centrality(self, top_n: int = 10) -> Dict:
        """
        ì¤‘ì‹¬ì„± ë¶„ì„ - ê°€ì¥ ì˜í–¥ë ¥ ìˆëŠ” ê¸°ì—… ì°¾ê¸°
        Returns: ë‹¤ì–‘í•œ ì¤‘ì‹¬ì„± ì§€í‘œë³„ ìƒìœ„ ê¸°ì—…
        """
        if self.local_graph.number_of_nodes() == 0:
            self.build_local_graph()
        
        if self.local_graph.number_of_nodes() == 0:
            return {"error": "ê·¸ë˜í”„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}
        
        try:
            # ì—°ê²° ì¤‘ì‹¬ì„± (Degree Centrality) - ì§ì ‘ ì—°ê²°ëœ ê´€ê³„ ìˆ˜
            degree_cent = nx.degree_centrality(self.local_graph)
            
            # ë§¤ê°œ ì¤‘ì‹¬ì„± (Betweenness Centrality) - ë‹¤ë¦¬ ì—­í• 
            betweenness_cent = nx.betweenness_centrality(self.local_graph)
            
            # ê·¼ì ‘ ì¤‘ì‹¬ì„± (Closeness Centrality) - ë‹¤ë¥¸ ë…¸ë“œì™€ì˜ í‰ê·  ê±°ë¦¬
            # DiGraphì—ì„œëŠ” ì—°ê²°ë˜ì§€ ì•Šì€ ë…¸ë“œê°€ ìˆì„ ìˆ˜ ìˆì–´ ì˜ˆì™¸ ì²˜ë¦¬
            try:
                closeness_cent = nx.closeness_centrality(self.local_graph)
            except:
                closeness_cent = {}
            
            # ìƒìœ„ Nê°œ ì¶”ì¶œ
            top_degree = sorted(degree_cent.items(), key=lambda x: x[1], reverse=True)[:top_n]
            top_betweenness = sorted(betweenness_cent.items(), key=lambda x: x[1], reverse=True)[:top_n]
            top_closeness = sorted(closeness_cent.items(), key=lambda x: x[1], reverse=True)[:top_n]
            
            return {
                "degree_centrality": [{"ticker": k, "score": round(v, 4)} for k, v in top_degree],
                "betweenness_centrality": [{"ticker": k, "score": round(v, 4)} for k, v in top_betweenness],
                "closeness_centrality": [{"ticker": k, "score": round(v, 4)} for k, v in top_closeness],
                "total_nodes": self.local_graph.number_of_nodes(),
                "total_edges": self.local_graph.number_of_edges(),
            }
            
        except Exception as e:
            logger.error(f"Error calculating centrality: {e}")
            return {"error": str(e)}

    def find_shortest_path(self, source_ticker: str, target_ticker: str) -> Dict:
        """
        ë‘ ê¸°ì—… ê°„ì˜ ìµœë‹¨ ê²½ë¡œ ì°¾ê¸°
        Returns: ê²½ë¡œì™€ ê´€ê³„ ìœ í˜•
        """
        if self.local_graph.number_of_nodes() == 0:
            self.build_local_graph()
        
        try:
            # ë°©í–¥ ë¬´ì‹œí•˜ê³  ê²½ë¡œ ì°¾ê¸° (undirected view)
            undirected = self.local_graph.to_undirected()
            
            if source_ticker not in undirected or target_ticker not in undirected:
                return {"error": f"'{source_ticker}' ë˜ëŠ” '{target_ticker}'ê°€ ê·¸ë˜í”„ì— ì—†ìŠµë‹ˆë‹¤."}
            
            # ìµœë‹¨ ê²½ë¡œ ì°¾ê¸°
            path = nx.shortest_path(undirected, source=source_ticker, target=target_ticker)
            
            # ê²½ë¡œì˜ ê° ì—£ì§€ ê´€ê³„ ìœ í˜• ì¶”ì¶œ
            path_details = []
            for i in range(len(path) - 1):
                node1, node2 = path[i], path[i + 1]
                
                # ì›ë˜ ë°©í–¥ ê·¸ë˜í”„ì—ì„œ ê´€ê³„ ì°¾ê¸°
                if self.local_graph.has_edge(node1, node2):
                    edge_data = self.local_graph.get_edge_data(node1, node2)
                    direction = "â†’"
                elif self.local_graph.has_edge(node2, node1):
                    edge_data = self.local_graph.get_edge_data(node2, node1)
                    direction = "â†"
                else:
                    edge_data = {}
                    direction = "â€”"
                
                path_details.append({
                    "from": node1,
                    "to": node2,
                    "direction": direction,
                    "relationship": edge_data.get("relationship_type", "related"),
                })
            
            return {
                "source": source_ticker,
                "target": target_ticker,
                "path": path,
                "path_length": len(path) - 1,
                "details": path_details,
            }
            
        except nx.NetworkXNoPath:
            return {"error": f"'{source_ticker}'ì™€ '{target_ticker}' ì‚¬ì´ì— ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤."}
        except Exception as e:
            logger.error(f"Error finding shortest path: {e}")
            return {"error": str(e)}

    def get_connected_companies(self, ticker: str, max_depth: int = 2) -> Dict:
        """
        íŠ¹ì • ê¸°ì—…ê³¼ ì—°ê²°ëœ ëª¨ë“  ê¸°ì—… ì°¾ê¸° (BFS)
        Returns: depthë³„ ì—°ê²°ëœ ê¸°ì—… ëª©ë¡
        """
        if self.local_graph.number_of_nodes() == 0:
            self.build_local_graph()
        
        if ticker not in self.local_graph:
            return {"error": f"'{ticker}'ê°€ ê·¸ë˜í”„ì— ì—†ìŠµë‹ˆë‹¤."}
        
        try:
            undirected = self.local_graph.to_undirected()
            
            # BFSë¡œ depthë³„ ë…¸ë“œ ì°¾ê¸°
            connected_by_depth = {}
            visited = {ticker}
            current_level = {ticker}
            
            for depth in range(1, max_depth + 1):
                next_level = set()
                for node in current_level:
                    neighbors = set(undirected.neighbors(node)) - visited
                    next_level.update(neighbors)
                    visited.update(neighbors)
                
                if next_level:
                    connected_by_depth[f"depth_{depth}"] = list(next_level)
                current_level = next_level
            
            return {
                "ticker": ticker,
                "connected": connected_by_depth,
                "total_connected": len(visited) - 1,  # ìê¸° ìì‹  ì œì™¸
            }
            
        except Exception as e:
            logger.error(f"Error finding connected companies: {e}")
            return {"error": str(e)}

    def get_stats(self) -> Dict:
        """Get statistics"""
        stats = {}

        try:
            companies = self.supabase.table("companies").select("id", count="exact").execute()
            relationships = (
                self.supabase.table("company_relationships").select("id", count="exact").execute()
            )
            documents = self.supabase.table("documents").select("id", count="exact").execute()

            stats = {
                "companies": companies.count or 0,
                "relationships": relationships.count or 0,
                "documents": documents.count or 0,
            }
        except Exception as e:
            stats["error"] = str(e)

        return stats


# LangGraph Tool function
def graph_search_tool(query: str, ticker: str = None) -> str:
    """
    íšŒì‚¬ ê´€ê³„ ê·¸ë˜í”„ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    LangGraph Toolë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
    """
    try:
        graph_rag = GraphRAG()
        result = graph_rag.query_with_context(query, ticker)
        return result.get("response", "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"Graph search error: {e}")
        return f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}"


if __name__ == "__main__":
    print("ğŸ”„ GraphRAG ì´ˆê¸°í™” ì¤‘...")

    try:
        graph_rag = GraphRAG()
        stats = graph_rag.get_stats()

        print(f"âœ… GraphRAG ì´ˆê¸°í™” ì„±ê³µ!")
        print(f"   Companies: {stats.get('companies', 'N/A')}")
        print(f"   Relationships: {stats.get('relationships', 'N/A')}")
        print(f"   Documents: {stats.get('documents', 'N/A')}")

        if "error" in stats:
            print(f"   âš ï¸ Error: {stats['error']}")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
