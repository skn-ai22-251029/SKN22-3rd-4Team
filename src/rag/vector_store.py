"""
Vector store for document embeddings and similarity search using Supabase
Uses Supabase REST API with pgvector extension
Enhanced with CrossEncoder Reranking for improved search accuracy
"""

import logging
import os
from typing import List, Dict, Optional, Tuple
from openai import OpenAI
from supabase import create_client, Client
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)

# CrossEncoder ëª¨ë¸ (Lazy Loading)
_reranker = None


class VectorStore:
    """Manages vector embeddings for financial documents using Supabase pgvector"""

    def __init__(
        self,
        table_name: str = "documents",
        embedding_model: str = "text-embedding-3-small",
        dimension: int = 1536,
    ):
        """
        Initialize vector store with Supabase

        Args:
            table_name: Name of the table in Supabase
            embedding_model: Model for generating embeddings
            dimension: Embedding dimension (1536 for text-embedding-3-small)
        """
        self.table_name = table_name
        self.embedding_model = embedding_model
        self.dimension = dimension

        # Get Supabase credentials
        supabase_url = os.getenv("SUPABASE_URL")
        supabase_key = os.getenv("SUPABASE_KEY")

        if not supabase_url or not supabase_key:
            raise ValueError("SUPABASE_URLê³¼ SUPABASE_KEY í™˜ê²½ ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        # Initialize Supabase client
        self.supabase: Client = create_client(supabase_url, supabase_key)

        # Initialize OpenAI client for embeddings
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        if not self.openai_api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        self.openai_client = OpenAI(api_key=self.openai_api_key)

        logger.info(f"Initialized Supabase vector store with table: {table_name}")

    def _get_embedding(self, text: str) -> List[float]:
        """Generate embedding for a single text"""
        response = self.openai_client.embeddings.create(
            model=self.embedding_model, input=text
        )
        return response.data[0].embedding

    def _get_embeddings(self, texts: List[str]) -> List[List[float]]:
        """Generate embeddings for multiple texts"""
        response = self.openai_client.embeddings.create(
            model=self.embedding_model, input=texts
        )
        return [item.embedding for item in response.data]

    def add_documents(self, documents: List[Dict], batch_size: int = 100) -> int:
        """
        Add documents to the vector store

        Args:
            documents: List of document dictionaries with 'id', 'text', and 'metadata'
            batch_size: Number of documents to process at once

        Returns:
            Number of documents added
        """
        total_added = 0

        for i in range(0, len(documents), batch_size):
            batch = documents[i : i + batch_size]

            texts = [doc.get("text", "") for doc in batch]

            try:
                # Generate embeddings
                embeddings = self._get_embeddings(texts)

                # Prepare records for Supabase
                records = []
                for j, doc in enumerate(batch):
                    record = {
                        "content": doc.get("text", ""),
                        "embedding": embeddings[j],
                        "metadata": doc.get("metadata", {}),
                    }
                    if "id" in doc:
                        record["id"] = doc["id"]
                    records.append(record)

                # Insert to Supabase
                self.supabase.table(self.table_name).insert(records).execute()

                total_added += len(batch)
                logger.info(f"Added batch {i // batch_size + 1}, total: {total_added}")

            except Exception as e:
                logger.error(f"Error adding batch {i // batch_size + 1}: {str(e)}")

        logger.info(f"Total documents added: {total_added}")
        return total_added

    def similarity_search(
        self, query: str, k: int = 5, filter_dict: Optional[Dict] = None
    ) -> List[Dict]:
        """
        Search for similar documents using pgvector

        Args:
            query: Search query
            k: Number of results to return
            filter_dict: Optional metadata filters

        Returns:
            List of similar documents with scores
        """
        try:
            # Generate query embedding
            query_embedding = self._get_embedding(query)

            # Call the match_documents function in Supabase
            # Note: Adding match_threshold to disambiguate function overload
            response = self.supabase.rpc(
                "match_documents",
                {
                    "query_embedding": query_embedding,
                    "match_count": k,
                    "match_threshold": 0.1,  # Threshold ë‚®ì¶¤ (0.5 -> 0.1)
                },
            ).execute()

            # ë””ë²„ê¹…: ì‘ë‹µ ë°ì´í„° ë¡œê¹…
            if not response.data:
                logger.warning(f"No results from match_documents. Response: {response}")

            # Format results
            documents = []
            for item in response.data:
                documents.append(
                    {
                        "id": item.get("id"),
                        "content": item.get("content"),
                        "metadata": item.get("metadata"),
                        "similarity": item.get("similarity"),
                    }
                )

            return documents

        except Exception as e:
            logger.error(f"Error in similarity search: {str(e)}")
            import traceback

            traceback.print_exc()
            return []

    def _load_reranker(self):
        """CrossEncoder ëª¨ë¸ ë¡œë“œ (Lazy Loading)"""
        global _reranker
        if _reranker is None:
            try:
                from sentence_transformers import CrossEncoder

                _reranker = CrossEncoder("cross-encoder/ms-marco-MiniLM-L-6-v2")
                logger.info("CrossEncoder reranker loaded successfully")
            except ImportError:
                logger.warning(
                    "sentence-transformers not installed. Reranking will be disabled."
                )
                return None
        return _reranker

    def rerank_results(
        self, query: str, documents: List[Dict], top_k: int = 5
    ) -> List[Dict]:
        """
        CrossEncoderë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ ì¬ì •ë ¬

        Args:
            query: ì›ë³¸ ì§ˆë¬¸
            documents: Vector Search ê²°ê³¼
            top_k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜

        Returns:
            ì¬ì •ë ¬ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        if not documents:
            return []

        reranker = self._load_reranker()
        if reranker is None:
            return documents[:top_k]

        try:
            # CrossEncoderëŠ” (query, document) ìŒì˜ ì ìˆ˜ë¥¼ ê³„ì‚°
            pairs = [(query, doc.get("content", "")[:1000]) for doc in documents]
            scores = reranker.predict(pairs)

            # ì ìˆ˜ì™€ ë¬¸ì„œë¥¼ í•¨ê»˜ ì •ë ¬
            scored_docs = list(zip(documents, scores))
            scored_docs.sort(key=lambda x: x[1], reverse=True)

            # ìƒìœ„ top_k ë¬¸ì„œ ë°˜í™˜ (rerank_score ì¶”ê°€ ë° ìŒìˆ˜ ì ìˆ˜ í•„í„°ë§)
            reranked = []
            for doc, score in scored_docs:
                if score < 0:  # ê´€ë ¨ì„± ì—†ëŠ” ë¬¸ì„œ(ìŒìˆ˜ ì ìˆ˜) ì œê±°
                    continue

                doc["rerank_score"] = float(score)
                reranked.append(doc)

                if len(reranked) >= top_k:
                    break

            logger.info(f"Reranked {len(documents)} docs â†’ top {top_k}")
            return reranked

        except Exception as e:
            logger.error(f"Reranking failed: {e}")
            return documents[:top_k]

    def similarity_search_with_rerank(
        self,
        query: str,
        k: int = 5,
        initial_k: int = 20,
        filter_dict: Optional[Dict] = None,
    ) -> List[Dict]:
        """
        Vector Search + Reranking í†µí•© ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ ì§ˆë¬¸
            k: ìµœì¢… ë°˜í™˜ ë¬¸ì„œ ìˆ˜
            initial_k: 1ì°¨ Vector Searchì—ì„œ ê°€ì ¸ì˜¬ ë¬¸ì„œ ìˆ˜
            filter_dict: ë©”íƒ€ë°ì´í„° í•„í„°

        Returns:
            ì¬ì •ë ¬ëœ ìƒìœ„ kê°œ ë¬¸ì„œ
        """
        # 1. ë¨¼ì € ë” ë§ì€ ë¬¸ì„œë¥¼ Vector Searchë¡œ ê°€ì ¸ì˜´
        initial_results = self.similarity_search(query, initial_k, filter_dict)

        # 2. CrossEncoderë¡œ ì¬ì •ë ¬
        reranked_results = self.rerank_results(query, initial_results, k)

        return reranked_results

    def search_by_company(self, query: str, company: str, k: int = 5) -> List[Dict]:
        """
        Search for documents related to a specific company

        Args:
            query: Search query
            company: Company ticker or name
            k: Number of results

        Returns:
            List of relevant documents
        """
        # For now, do a general search and filter by company
        results = self.similarity_search(query, k * 2)

        # Filter by company ticker in metadata
        filtered = [
            doc for doc in results if doc.get("metadata", {}).get("ticker") == company
        ]

        return filtered[:k]

    def hybrid_search(
        self,
        query: str,
        k: int = 5,
        vector_weight: float = 0.7,
        keyword_weight: float = 0.3,
    ) -> List[Dict]:
        """
        Hybrid Search: Vector(ì˜ë¯¸) + Keyword(BM25) ê²°í•©

        Args:
            query: ê²€ìƒ‰ ì§ˆë¬¸
            k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
            vector_weight: Vector ê²€ìƒ‰ ê°€ì¤‘ì¹˜ (ê¸°ë³¸ 0.7)
            keyword_weight: Keyword ê²€ìƒ‰ ê°€ì¤‘ì¹˜ (ê¸°ë³¸ 0.3)

        Returns:
            ê²°í•©ëœ ê²€ìƒ‰ ê²°ê³¼
        """
        try:
            # 1. Vector Search ê²°ê³¼
            vector_results = self.similarity_search(query, k * 2)
            vector_ids = {doc["id"]: (i, doc) for i, doc in enumerate(vector_results)}

            # 2. Keyword Search (Supabase Full-Text Search)
            # PostgreSQLì˜ to_tsqueryë¥¼ ì‚¬ìš©í•˜ì—¬ í‚¤ì›Œë“œ ê²€ìƒ‰
            keywords = " | ".join(query.split()[:5])  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œë§Œ ì‚¬ìš©

            try:
                # Supabase Full-Text Search ëŒ€ì‹  ILIKE íŒ¨í„´ ë§¤ì¹­ ì‚¬ìš©
                # (ë” í˜¸í™˜ì„±ì´ ì¢‹ìŒ)
                search_pattern = f"%{query.split()[0]}%"  # ì²« ë²ˆì§¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰
                keyword_response = (
                    self.supabase.table(self.table_name)
                    .select("id, content, metadata")
                    .ilike("content", search_pattern)
                    .limit(k * 2)
                    .execute()
                )
                keyword_results = keyword_response.data or []
            except Exception as e:
                logger.warning(f"Keyword search failed, using vector only: {e}")
                keyword_results = []

            keyword_ids = {doc["id"]: (i, doc) for i, doc in enumerate(keyword_results)}

            # 3. RRF (Reciprocal Rank Fusion) ìŠ¤ì½”ì–´ ê³„ì‚°
            rrf_scores = {}
            RRF_K = 60  # RRF ìƒìˆ˜

            for doc_id, (rank, doc) in vector_ids.items():
                rrf_scores[doc_id] = {
                    "doc": doc,
                    "score": vector_weight * (1 / (RRF_K + rank)),
                }

            for doc_id, (rank, doc) in keyword_ids.items():
                if doc_id in rrf_scores:
                    rrf_scores[doc_id]["score"] += keyword_weight * (1 / (RRF_K + rank))
                else:
                    rrf_scores[doc_id] = {
                        "doc": {
                            "id": doc_id,
                            "content": doc.get("content"),
                            "metadata": doc.get("metadata"),
                            "similarity": 0,
                        },
                        "score": keyword_weight * (1 / (RRF_K + rank)),
                    }

            # 4. RRF ìŠ¤ì½”ì–´ë¡œ ì •ë ¬
            sorted_results = sorted(
                rrf_scores.values(), key=lambda x: x["score"], reverse=True
            )

            # 5. ìƒìœ„ í›„ë³´êµ° ì¶”ì¶œ (Reranking ì „)
            # Rerankingì„ ìœ„í•´ kë³´ë‹¤ ì¡°ê¸ˆ ë” ë§ì´ ê°€ì ¸ì˜´
            candidates = []
            for item in sorted_results[: k * 2]:
                doc = item["doc"]
                doc["hybrid_score"] = item["score"]
                candidates.append(doc)

            # 6. CrossEncoderë¡œ ìµœì¢… ì¬ì •ë ¬ (Hybrid + Reranking)
            try:
                final_results = self.rerank_results(query, candidates, k)
                logger.info(
                    f"Hybrid Search: {len(vector_results)} vec + {len(keyword_results)} key -> {len(candidates)} cand -> {len(final_results)} reranked"
                )
                return final_results
            except Exception as e:
                logger.warning(f"Reranking in hybrid search failed: {e}")
                return candidates[:k]

            logger.info(
                f"Hybrid search: {len(vector_results)} vector + {len(keyword_results)} keyword â†’ {len(final_results)} combined"
            )
            return final_results

        except Exception as e:
            logger.error(f"Hybrid search failed: {e}")
            # Fallback to reranked vector search
            return self.similarity_search_with_rerank(query, k)

    def get_stats(self) -> Dict:
        """Get statistics about the table"""
        try:
            response = (
                self.supabase.table(self.table_name)
                .select("id", count="exact")
                .execute()
            )
            count = response.count if response.count else 0
        except Exception:
            count = "Unknown"

        return {
            "table_name": self.table_name,
            "total_documents": count,
            "embedding_model": self.embedding_model,
            "dimension": self.dimension,
        }


# RAG Tool function for LangGraph
def rag_search_tool(query: str, ticker: str = None, k: int = 5) -> str:
    """
    Supabase Vector Storeì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    LangGraph Toolë¡œ ì‚¬ìš©ë  í•¨ìˆ˜ì…ë‹ˆë‹¤.
    """
    try:
        vector_store = VectorStore()

        if ticker:
            results = vector_store.search_by_company(query, ticker, k)
        else:
            results = vector_store.similarity_search(query, k)

        if not results:
            return "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        context = "\n---\n".join(
            [
                f"ë‚´ìš©: {doc.get('content', 'N/A')[:500]}...\në©”íƒ€ë°ì´í„°: {doc.get('metadata', {})}"
                for doc in results
            ]
        )

        return context

    except Exception as e:
        logger.error(f"RAG search error: {str(e)}")
        return f"ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸: Vector Store ì´ˆê¸°í™” ë° í†µê³„ í™•ì¸
    try:
        print("ğŸ”„ Vector Store ì—°ê²° ì¤‘...")
        store = VectorStore()
        stats = store.get_stats()
        print(f"âœ… Vector Store ì—°ê²° ì„±ê³µ!")
        print(f"   Table: {stats['table_name']}")
        print(f"   Documents: {stats['total_documents']}")
        print(f"   Embedding Model: {stats['embedding_model']}")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
